/**
 * io.net Intelligence API Service for Edgen Helper AI Chatbot
 * Integrates with io.net Intelligence API using Llama-3.3-70B-Instruct model
 * Reference: https://docs.io.net/reference/get-started-with-io-intelligence-api
 * Model: meta-llama/Llama-3.3-70B-Instruct
 */

export interface IoNetConfig {
  apiKey: string
  baseUrl: string
  model: string
  maxTokens: number
  temperature: number
  topP: number
}

export interface ChatMessage {
  role: 'system' | 'user' | 'assistant'
  content: string
  timestamp?: Date
}

export interface ChatResponse {
  success: boolean
  message?: string
  error?: string
  usage?: {
    promptTokens: number
    completionTokens: number
    totalTokens: number
  }
  model?: string
  finishReason?: string
}

export class IoNetApiService {
  private config: IoNetConfig
  private isInitialized: boolean = false

  constructor(config?: Partial<IoNetConfig>) {
    this.config = {
      apiKey: process.env.IO_NET_API_KEY || '',
      baseUrl: process.env.IO_NET_BASE_URL || 'https://api.intelligence.io.solutions/api',
      model: process.env.IO_NET_MODEL || 'meta-llama/Llama-3.3-70B-Instruct',
      maxTokens: parseInt(process.env.EDGEN_HELPER_MAX_TOKENS || '1000'),
      temperature: parseFloat(process.env.EDGEN_HELPER_TEMPERATURE || '0.7'),
      topP: parseFloat(process.env.EDGEN_HELPER_TOP_P || '0.9'),
      ...config
    }

    if (!this.config.apiKey) {
      console.warn('‚ö†Ô∏è io.net Intelligence API key not configured')
      console.warn('Environment check:', {
        IO_NET_API_KEY: process.env.IO_NET_API_KEY ? 'Present' : 'Missing',
        IO_NET_BASE_URL: process.env.IO_NET_BASE_URL || 'Missing',
        IO_NET_MODEL: process.env.IO_NET_MODEL || 'Missing'
      })
      this.isInitialized = false
    } else {
      this.isInitialized = true
      console.log('‚úÖ io.net Intelligence API service initialized with Llama-3.3-70B-Instruct')
      console.log(`üì° Base URL: ${this.config.baseUrl}`)
      console.log(`ü§ñ Model: ${this.config.model}`)
      console.log(`üîë API Key: ${this.config.apiKey.substring(0, 20)}...`)
    }
  }

  /**
   * Get the system prompt for Edgen Helper (optimized for Llama-3.3-70B-Instruct)
   */
  private getSystemPrompt(): string {
    return `You are "Edgen Helper", an intelligent AI assistant powered by Llama-3.3-70B-Instruct for the LayerEdge community platform.

CORE MISSION: Help LayerEdge community members maximize their engagement and earn points through strategic tweet submission.

PLATFORM OVERVIEW:
LayerEdge is a community-driven platform for \\$EDGEN token holders where users earn points by submitting high-engagement tweets containing specific mentions.

RESPONSE STYLE:
- Be direct, helpful, and engaging
- Use emojis and LayerEdge branding appropriately
- Provide actionable guidance
- Match the user's energy level
- No meta-commentary or planning - just helpful responses

KEY FEATURES YOU SUPPORT:

1. **Points System**: Users earn points by submitting tweets with @layeredge OR \\$EDGEN mentions. Points = base score + engagement multiplier (likes + retweets + replies).

2. **Tweet Submission**: Guide users to /submit page where they paste direct tweet URLs. System validates mentions and tracks engagement.

3. **Hashtag Strategy**: @layeredge (official mention) or \\$EDGEN (token reference) - either qualifies for points.

4. **Troubleshooting**: Help with common issues like invalid URLs, tweet not found, missing points, or login problems.

5. **Best Practices**: Encourage authentic content, genuine engagement, and respectful community participation.

GUIDELINES:
- Be helpful and actionable
- Use Bitcoin orange (#f7931a) branding when relevant
- Direct users to /submit page for tweet submission
- Keep responses clean and professional
- Match user energy (casual/formal as appropriate)

If unsure about technical details, recommend contacting platform support.`
  }

  /**
   * Send a chat message to io.net Intelligence API
   * Uses Llama-3.3-70B-Instruct model through io.net's infrastructure
   */
  async sendMessage(userMessage: string, conversationHistory: ChatMessage[] = []): Promise<ChatResponse> {
    if (!this.isInitialized) {
      return {
        success: false,
        error: 'io.net Intelligence API service not initialized. Please check your API key configuration.'
      }
    }

    try {
      console.log('ü§ñ Sending message to io.net Intelligence API with Llama-3.3-70B-Instruct...')

      // Prepare messages array with system prompt
      const messages: ChatMessage[] = [
        {
          role: 'system',
          content: this.getSystemPrompt()
        },
        ...conversationHistory.slice(-8), // Keep last 8 messages for context (Llama optimization)
        {
          role: 'user',
          content: userMessage
        }
      ]

      // Prepare request payload according to io.net Intelligence API documentation
      const requestPayload = {
        model: this.config.model, // meta-llama/Llama-3.3-70B-Instruct
        messages: messages.map(msg => ({
          role: msg.role,
          content: msg.content
        })),
        max_tokens: this.config.maxTokens,
        temperature: this.config.temperature,
        top_p: this.config.topP,
        stream: false,
        // Llama-3.3-70B-Instruct specific parameters
        stop: null,
        presence_penalty: 0,
        frequency_penalty: 0
      }

      console.log('üì§ Request payload prepared for io.net Intelligence API')
      console.log(`üéØ Using model: ${this.config.model}`)

      // Make API request to io.net Intelligence API
      console.log(`üåê Making request to: ${this.config.baseUrl}/v1/chat/completions`)
      console.log(`üìã Request payload:`, {
        model: requestPayload.model,
        messages: requestPayload.messages.length,
        max_tokens: requestPayload.max_tokens,
        temperature: requestPayload.temperature
      })

      const response = await fetch(`${this.config.baseUrl}/v1/chat/completions`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.config.apiKey}`,
          'Content-Type': 'application/json',
          'Accept': 'application/json',
          'User-Agent': 'LayerEdge-EdgenHelper/2.0'
        },
        body: JSON.stringify(requestPayload)
      })

      if (!response.ok) {
        let errorText = ''
        try {
          const errorData = await response.json()
          errorText = errorData.error?.message || errorData.message || JSON.stringify(errorData)
        } catch {
          errorText = await response.text()
        }

        console.error('‚ùå io.net Intelligence API error:', response.status, errorText)

        // Handle specific error cases
        if (response.status === 401) {
          return {
            success: false,
            error: 'Authentication failed. Please check your io.net API key.'
          }
        } else if (response.status === 429) {
          return {
            success: false,
            error: 'Rate limit exceeded. Please try again in a moment.'
          }
        } else if (response.status === 400) {
          return {
            success: false,
            error: 'Invalid request format. Please check the message content.'
          }
        }

        return {
          success: false,
          error: `io.net Intelligence API error: ${response.status} - ${errorText}`
        }
      }

      const data = await response.json()
      console.log('‚úÖ Received response from io.net Intelligence API')

      // Extract the assistant's message according to OpenAI-compatible format
      const choice = data.choices?.[0]
      const assistantMessage = choice?.message?.content

      if (!assistantMessage) {
        console.error('‚ùå No content in API response:', data)
        return {
          success: false,
          error: 'No response content received from io.net Intelligence API'
        }
      }

      return {
        success: true,
        message: assistantMessage,
        model: data.model || this.config.model,
        finishReason: choice?.finish_reason,
        usage: data.usage ? {
          promptTokens: data.usage.prompt_tokens || 0,
          completionTokens: data.usage.completion_tokens || 0,
          totalTokens: data.usage.total_tokens || 0
        } : undefined
      }

    } catch (error) {
      console.error('‚ùå io.net Intelligence API service error:', error)

      // Handle network errors
      if (error instanceof TypeError && error.message.includes('fetch')) {
        return {
          success: false,
          error: 'Network error: Unable to connect to io.net Intelligence API'
        }
      }

      return {
        success: false,
        error: error instanceof Error ? error.message : 'Unknown error occurred'
      }
    }
  }

  /**
   * Get a comprehensive fallback response when API is unavailable
   */
  getFallbackResponse(userMessage: string): ChatResponse {
    const message = userMessage.toLowerCase()

    // Provide comprehensive responses for common questions
    if (message.includes('points') || message.includes('earn')) {
      return {
        success: true,
        message: "üéØ **How to Earn Points on LayerEdge:**\n\n1. **Submit Tweets**: Go to `/submit` page and paste your tweet URL\n2. **Required Mentions**: Your tweet must contain `@layeredge` OR `\\$EDGEN`\n3. **Engagement Matters**: Points = base score + (likes + retweets + replies)\n4. **Community Verification**: Only verified community members earn points\n\nüí° **Pro Tip**: Higher engagement = more points! Focus on creating quality content that resonates with the LayerEdge community.\n\n*Note: I'm currently in enhanced offline mode with comprehensive responses.*"
      }
    }

    if (message.includes('submit') || message.includes('tweet')) {
      return {
        success: true,
        message: "üìù **Tweet Submission Guide:**\n\n**Step 1**: Create a tweet containing `@layeredge` or `\\$EDGEN`\n**Step 2**: Copy the direct tweet URL (format: https://x.com/username/status/1234567890)\n**Step 3**: Visit `/submit` page on LayerEdge platform\n**Step 4**: Paste your tweet URL and click submit\n**Step 5**: Wait for verification and point calculation\n\n‚ö†Ô∏è **Common Issues**:\n- Use direct tweet URLs, not profile or search URLs\n- Ensure tweet is public and accessible\n- Verify you included required mentions\n\n*Enhanced offline assistance active.*"
      }
    }

    if (message.includes('hashtag') || message.includes('@layeredge') || message.includes('$edgen')) {
      return {
        success: true,
        message: "üè∑Ô∏è **LayerEdge Hashtag Strategy:**\n\n**@layeredge**: Official account mention\n- Use when referencing the platform\n- Great for community engagement\n- Increases visibility\n\n**\\$EDGEN**: Token reference\n- Use when discussing the token\n- Shows community involvement\n- Attracts token holders\n\n**Best Practices**:\n- You only need ONE of these mentions (not both)\n- Case-insensitive matching\n- Natural integration works best\n- Combine with relevant content\n\n*Comprehensive offline guidance available.*"
      }
    }

    if (message.includes('troubleshoot') || message.includes('problem') || message.includes('issue')) {
      return {
        success: true,
        message: "üîß **LayerEdge Troubleshooting:**\n\n**Tweet Submission Issues**:\n- ‚ùå Invalid URL ‚Üí Use direct tweet links\n- ‚ùå Tweet not found ‚Üí Check if tweet is public\n- ‚ùå No points awarded ‚Üí Verify @layeredge or \\$EDGEN mention\n- ‚ùå Login problems ‚Üí Reconnect your X/Twitter account\n\n**Common Solutions**:\n1. Refresh the page and try again\n2. Check your internet connection\n3. Verify tweet URL format\n4. Ensure tweet contains required mentions\n5. Contact support if issues persist\n\n*Advanced troubleshooting in offline mode.*"
      }
    }

    if (message.includes('hello') || message.includes('hi') || message.includes('help')) {
      return {
        success: true,
        message: "üëã **Welcome to Edgen Helper!**\n\nI'm your LayerEdge community assistant, currently running in **Enhanced Offline Mode** with comprehensive responses.\n\nüéØ **I can help you with**:\n‚Ä¢ Tweet submission and optimization\n‚Ä¢ Points system and earning strategies\n‚Ä¢ @layeredge and \\$EDGEN hashtag usage\n‚Ä¢ Platform navigation and features\n‚Ä¢ Troubleshooting common issues\n\nüí¨ **Try asking me**:\n- \"How do I earn points?\"\n- \"How to submit a tweet?\"\n- \"What hashtags should I use?\"\n- \"I'm having issues with...\"\n\n*Enhanced AI responses available even offline!*"
      }
    }

    return {
      success: true,
      message: "ü§ñ **Edgen Helper - Enhanced Offline Mode**\n\nI'm your LayerEdge community assistant with comprehensive offline capabilities!\n\nüéØ **Quick Help**:\n‚Ä¢ **Earn Points**: Submit tweets with @layeredge or \\$EDGEN\n‚Ä¢ **Submit Tweets**: Visit `/submit` page\n‚Ä¢ **Check Points**: View your dashboard\n‚Ä¢ **Get Help**: Ask me specific questions\n\nüí° **Popular Topics**: Points system, tweet submission, hashtag strategy, troubleshooting\n\n*Ask me anything about LayerEdge - I have enhanced offline responses ready!*"
    }
  }

  /**
   * Test the io.net Intelligence API connection
   */
  async testConnection(): Promise<boolean> {
    if (!this.isInitialized) {
      console.log('‚ùå io.net Intelligence API not initialized')
      return false
    }

    try {
      console.log('üîç Testing io.net Intelligence API connection...')
      const testResponse = await this.sendMessage('Hello, this is a connection test for Llama-3.3-70B-Instruct.')

      if (testResponse.success) {
        console.log('‚úÖ io.net Intelligence API connection successful')
        console.log(`ü§ñ Model confirmed: ${testResponse.model || this.config.model}`)
        return true
      } else {
        console.log('‚ùå io.net Intelligence API connection failed:', testResponse.error)
        return false
      }
    } catch (error) {
      console.error('‚ùå io.net Intelligence API connection test failed:', error)
      return false
    }
  }

  /**
   * Get service status
   */
  getStatus(): {
    initialized: boolean
    apiKey: string
    baseUrl: string
    model: string
    ready: boolean
    maxTokens: number
    temperature: number
    topP: number
  } {
    return {
      initialized: this.isInitialized,
      apiKey: this.config.apiKey ? `${this.config.apiKey.substring(0, 15)}...` : 'Not set',
      baseUrl: this.config.baseUrl,
      model: this.config.model,
      ready: this.isInitialized,
      maxTokens: this.config.maxTokens,
      temperature: this.config.temperature,
      topP: this.config.topP
    }
  }

  /**
   * Check if service is ready
   */
  isReady(): boolean {
    return this.isInitialized
  }
}

// Singleton instance
let ionetApiServiceInstance: IoNetApiService | null = null

/**
 * Get io.net API service instance
 */
export function getIoNetApiService(): IoNetApiService {
  if (!ionetApiServiceInstance) {
    ionetApiServiceInstance = new IoNetApiService()
  }
  return ionetApiServiceInstance
}

/**
 * Initialize io.net API service with custom config
 */
export function initializeIoNetApiService(config: Partial<IoNetConfig>): IoNetApiService {
  ionetApiServiceInstance = new IoNetApiService(config)
  return ionetApiServiceInstance
}
